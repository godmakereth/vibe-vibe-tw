---
title: "12.3.5 é«˜ç´šæ‡‰ç”¨å ´æ™¯â€”â€”RAG èˆ‡å¤šæ¨¡æ…‹ï¼šæª¢ç´¢å¢å¼·ç”Ÿæˆèˆ‡åœ–æ–‡æ··åˆ"
typora-root-url: ../../public
---

# 12.3.5 é«˜ç´šæ‡‰ç”¨å ´æ™¯â€”â€”RAG èˆ‡å¤šæ¨¡æ…‹ï¼šæª¢ç´¢å¢å¼·ç”Ÿæˆèˆ‡åœ–æ–‡æ··åˆ

### ä¸€å¥è©±ç ´é¡Œ

RAG è®“ AI èƒ½"æŸ¥é–±è³‡æ–™"å¾Œå›ç­”å•é¡Œï¼Œå¤šæ¨¡æ…‹è®“ AI èƒ½"çœ‹åœ–èªªè©±"â€”â€”é€™å…©é …æŠ€è¡“å¤§å¹…æ“´å±•äº† AI æ‡‰ç”¨çš„èƒ½åŠ›é‚Šç•Œã€‚

### RAGï¼šæª¢ç´¢å¢å¼·ç”Ÿæˆ

#### ä»€éº¼æ˜¯ RAGï¼Ÿ

```mermaid
graph LR
    A["ç”¨æˆ¶æå•"] --> B["æª¢ç´¢ç›¸é—œæ–‡æª”"]
    B --> C["å°‡æ–‡æª”ä½œçˆ²ä¸Šä¸‹æ–‡"]
    C --> D["AI åŸºæ–¼ä¸Šä¸‹æ–‡å›ç­”"]
    D --> E["è¿”å›ç­”æ¡ˆ"]
```

RAG çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š**å…ˆæœç´¢ï¼Œå†å›ç­”**ã€‚é€™è§£æ±ºäº† AI çŸ¥è­˜éæ™‚ã€ç„¡æ³•è¨ªå•ç§æœ‰æ•¸æ“šç­‰å•é¡Œã€‚

#### åŸºç¤å¯¦ç¾

```typescript
// app/api/chat/route.ts
import { openai } from '@ai-sdk/openai';
import { streamText } from 'ai';
import { searchDocuments } from '@/lib/search'; // ä½ çš„æœç´¢é‚è¼¯

export async function POST(req: Request) {
  const { messages } = await req.json();
  
  // ç²å–ç”¨æˆ¶æœ€æ–°å•é¡Œ
  const lastMessage = messages[messages.length - 1];
  
  // æª¢ç´¢ç›¸é—œæ–‡æª”
  const relevantDocs = await searchDocuments(lastMessage.content);
  
  // æ§‹å»ºä¸Šä¸‹æ–‡
  const context = relevantDocs
    .map((doc) => `---\n${doc.title}\n${doc.content}\n---`)
    .join('\n');

  const result = streamText({
    model: openai('gpt-4o'),
    system: `ä½ æ˜¯ä¸€å€‹çŸ¥è­˜åŠ©æ‰‹ã€‚è«‹æ ¹æ“šä»¥ä¸‹è³‡æ–™å›ç­”ç”¨æˆ¶å•é¡Œã€‚å¦‚æœè³‡æ–™ä¸­æ²’æœ‰ç›¸é—œä¿¡æ¯ï¼Œè«‹èª å¯¦åœ°èªªä¸çŸ¥é“ã€‚

åƒè€ƒè³‡æ–™ï¼š
${context}`,
    messages,
  });

  return result.toDataStreamResponse();
}
```

#### å‘é‡æœç´¢

æ›´é«˜ç´šçš„ RAG å¯¦ç¾æœƒä½¿ç”¨å‘é‡æ•¸æ“šåº«é€²è¡Œèªç¾©æœç´¢ï¼š

```typescript
import { embed } from 'ai';
import { openai } from '@ai-sdk/openai';

// ç”Ÿæˆæ–‡æœ¬åµŒå…¥
async function getEmbedding(text: string) {
  const { embedding } = await embed({
    model: openai.embedding('text-embedding-3-small'),
    value: text,
  });
  return embedding;
}

// åœ¨å‘é‡æ•¸æ“šåº«ä¸­æœç´¢
async function semanticSearch(query: string) {
  const queryEmbedding = await getEmbedding(query);
  
  // ä½¿ç”¨ Pineconeã€Supabase Vector ç­‰é€²è¡Œç›¸ä¼¼åº¦æœç´¢
  const results = await vectorDB.search(queryEmbedding, { topK: 5 });
  
  return results;
}
```

### å¤šæ¨¡æ…‹ï¼šåœ–æ–‡æ··åˆ

#### ç™¼é€åœ–ç‰‡çµ¦ AI

```typescript
// app/api/vision/route.ts
import { openai } from '@ai-sdk/openai';
import { streamText } from 'ai';

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = streamText({
    model: openai('gpt-4o'), // æ”¯æŒè¦–è¦ºçš„æ¨¡å‹
    messages: messages.map((m) => ({
      role: m.role,
      content: m.image
        ? [
            { type: 'text', text: m.content },
            { type: 'image', image: m.image }, // base64 æˆ– URL
          ]
        : m.content,
    })),
  });

  return result.toDataStreamResponse();
}
```

#### å‰ç«¯ä¸Šå‚³åœ–ç‰‡

```tsx
'use client';

import { useChat } from 'ai/react';
import { useState } from 'react';

export default function VisionChat() {
  const { messages, append, isLoading } = useChat();
  const [input, setInput] = useState('');
  const [image, setImage] = useState<string | null>(null);

  const handleImageUpload = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (file) {
      const reader = new FileReader();
      reader.onloadend = () => {
        setImage(reader.result as string);
      };
      reader.readAsDataURL(file);
    }
  };

  const handleSubmit = () => {
    if (!input.trim() && !image) return;
    
    append({
      role: 'user',
      content: input,
      // æ“´å±•å­—æ®µï¼Œéœ€è¦åœ¨ API ç«¯è™•ç†
      data: { image },
    });
    
    setInput('');
    setImage(null);
  };

  return (
    <div>
      {/* æ¶ˆæ¯åˆ—è¡¨ */}
      
      <div className="flex gap-2 p-4">
        <input
          type="file"
          accept="image/*"
          onChange={handleImageUpload}
          className="hidden"
          id="image-upload"
        />
        <label htmlFor="image-upload" className="cursor-pointer">
          ğŸ“
        </label>
        
        {image && (
          <img src={image} alt="ä¸Šå‚³é è¦½" className="w-16 h-16 object-cover rounded" />
        )}
        
        <input
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="æè¿°é€™å¼µåœ–ç‰‡..."
          className="flex-1 p-2 border rounded"
        />
        
        <button onClick={handleSubmit} disabled={isLoading}>
          ç™¼é€
        </button>
      </div>
    </div>
  );
}
```

### AI å”ä½œæŒ‡å—

- **æ ¸å¿ƒæ„åœ–**ï¼šè®“ AI å¹«ä½ å¯¦ç¾ RAG æˆ–å¤šæ¨¡æ…‹åŠŸèƒ½ã€‚
- **éœ€æ±‚å®šç¾©å…¬å¼**ï¼š
  - RAGï¼š`"è«‹å¹«æˆ‘å¯¦ç¾ä¸€å€‹åŸºæ–¼å‘é‡æœç´¢çš„ RAG ç³»çµ±ï¼Œä½¿ç”¨ Supabase ä½œçˆ²å‘é‡æ•¸æ“šåº«ï¼Œç”¨æˆ¶å¯ä»¥ä¸Šå‚³ PDF æ–‡æª”ä¸¦é€²è¡Œå•ç­”ã€‚"`
  - å¤šæ¨¡æ…‹ï¼š`"è«‹å¹«æˆ‘å¯¦ç¾ä¸€å€‹æ”¯æŒåœ–ç‰‡ä¸Šå‚³çš„ AI èŠå¤©ç•Œé¢ï¼Œç”¨æˆ¶å¯ä»¥ä¸Šå‚³åœ–ç‰‡ä¸¦è©¢å•åœ–ç‰‡å…§å®¹ã€‚"`
- **é—œéµè¡“èª**ï¼š`RAG`ã€`embedding`ã€`å‘é‡æœç´¢`ã€`å¤šæ¨¡æ…‹ (multimodal)`ã€`vision`

### é¿å‘æŒ‡å—

- **RAG çš„æª¢ç´¢è³ªé‡æ±ºå®šå›ç­”è³ªé‡**ï¼šåƒåœ¾é€²ï¼Œåƒåœ¾å‡ºã€‚
- **åœ–ç‰‡å¤§å°é™åˆ¶**ï¼šå¤§åœ–ç‰‡æœƒæ¶ˆè€—å¤§é‡ Tokenï¼Œå»ºè­°å£“ç¸®å¾Œä¸Šå‚³ã€‚
- **å‘é‡æ•¸æ“šåº«é¸æ“‡**ï¼šè€ƒæ…®æˆæœ¬ã€æ€§èƒ½å’Œæ˜“ç”¨æ€§çš„å¹³è¡¡ã€‚
- **ä¸Šä¸‹æ–‡çª—å£é™åˆ¶**ï¼šæª¢ç´¢çš„æ–‡æª”ä¸èƒ½å¤ªé•·ï¼Œå¦å‰‡æœƒè¶…å‡ºæ¨¡å‹é™åˆ¶ã€‚
