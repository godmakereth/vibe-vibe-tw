---
title: "5.3.5 AI 推薦的庫安全嗎（Slopsquatting）"
order: 7
---

# 5.3.5 AI 推薦的庫安全嗎？

經過本節學習，你將瞭解：
- 什麼是 Slopsquatting 攻擊
- 爲什麼 AI 推薦的庫可能有風險
- 如何驗證一個庫是否安全
- 真實的惡意包案例

## 還記得 AI 幻覺嗎？

在第三章，我們討論過 AI 有時會"一本正經地胡說八道"——給出看起來合理但實際上錯誤的回答。

在安全領域，這種"幻覺"會造成嚴重後果。

**AI 可能會推薦根本不存在的軟件包。**

根據德克薩斯大學等研究機構 2025 年的研究：
- **19.7%** 的 AI 推薦的包實際上不存在
- 開源模型的幻覺率高達 **21.7%**
- 即使是 GPT 系列，也有 **5.2%** 的幻覺率
- **58%** 的幻覺包名會重複出現，可被預測

## 什麼是 Slopsquatting？

**Slopsquatting** 是 2024-2025 年出現的新型攻擊方式，名字來源於：
- **Slop**：指 AI 生成的"廢話"或錯誤內容
- **Squatting**：搶注（就像域名搶注一樣）

**攻擊原理**：

```
1. 攻擊者研究 AI 常"幻覺"出的包名
   （比如 AI 經常推薦一個叫 "aws-helper-sdk" 的包，但它不存在）

2. 攻擊者搶先註冊這個包名
   （在 npm 或 PyPI 上創建一個真實的 "aws-helper-sdk" 包）

3. 在包中植入惡意代碼
   （比如竊取環境變量、下載後門程序）

4. 等待開發者上鉤
   （開發者信任 AI 推薦，直接安裝）

5. 惡意代碼被執行
   （開發者的密鑰、數據被盜取）
```

## 真實案例

### 案例一：aiocpa 惡意包（2024年11月）

Python 庫 **aiocpa**（一個加密貨幣支付 API 客戶端）被發現：
- 在 0.1.13 版本中植入了惡意代碼
- 會將用戶的 **Crypto Pay API Token** 通過 Telegram Bot 發送給攻擊者
- 該包在被發現前已被下載超過 **12,000 次**

### 案例二：solana-systemprogram-utils（2024年12月）

npm 上發現的惡意包：
- 僞裝成 Solana 區塊鏈的工具庫
- 會在 **2% 的交易中**，悄悄將資金轉到攻擊者地址
- 因爲比例低，很難被立即發現

### 案例三：GitHub Actions 供應鏈攻擊（2025年9月）

代號 **GhostAction** 的攻擊：
- 利用 AI 編程工具生成的 GitHub Actions 配置
- 從 **817 個倉庫**中竊取憑證
- 受影響的開發者超過 **5,500 人**

## 如何保護自己

### 步驟一：驗證包是否存在

安裝任何 AI 推薦的包之前，先去官方網站確認：

| 語言 | 官方包倉庫 | 網址 |
|------|-----------|------|
| JavaScript/Node.js | npm | npmjs.com |
| Python | PyPI | pypi.org |
| Go | Go Packages | pkg.go.dev |
| Rust | crates.io | crates.io |

### 步驟二：檢查包的可信度

在官方倉庫中搜索到包後，檢查：

| 指標 | 安全信號 | 警惕信號 |
|------|---------|---------|
| 下載量 | 周下載量較高（數千以上） | 下載量很低（幾十或更少） |
| 維護狀態 | 最近有更新 | 超過 2 年沒更新 |
| 作者 | 知名組織或有多個項目 | 只有這一個包，無其他活動 |
| 依賴者 | 被其他流行項目使用 | 沒有其他項目依賴 |
| 倉庫 | 有關聯的 GitHub 倉庫 | 沒有源碼倉庫 |

### 步驟三：警惕"新發現"的包

如果 AI 推薦了一個你從未聽過的包：

```
✅ 先在搜索引擎中搜索這個包名
✅ 看看是否有人在技術論壇或博客中討論過
✅ 檢查是否有官方文檔
✅ 如果找不到任何信息，很可能是幻覺
```

### 步驟四：仔細閱讀 AI 的推薦

有時候 AI 會給出這樣的建議：

```javascript
// AI 可能會說：
// "你可以使用 super-easy-auth 庫來處理認證"
npm install super-easy-auth
```

**在執行安裝命令之前**，先問自己：
- 這個庫我聽過嗎？
- 去 npmjs.com 搜索存在嗎？
- 下載量怎麼樣？

## 開源模型 vs 商業模型

研究表明，不同模型的幻覺率差異很大：

| 模型類型 | 幻覺率 | 說明 |
|---------|--------|------|
| 開源模型（如 CodeLlama） | ~21.7% | 每 5 個推薦中可能有 1 個是假的 |
| GPT 系列 | ~5.2% | 相對較低，但仍需警惕 |

**無論使用哪個模型，都應該驗證。**

## 記住這個原則

::: warning 核心原則
**AI 推薦的包 ≠ 存在的包 ≠ 安全的包**

在安裝任何新依賴之前，花 30 秒去官方倉庫驗證，可以避免很多麻煩。
:::

→ [5.3.6 永遠審查代碼](./5.3.6-always-review.md)
